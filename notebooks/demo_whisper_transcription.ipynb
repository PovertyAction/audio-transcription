{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "41864329",
            "metadata": {},
            "outputs": [],
            "source": [
                "import time\n",
                "\n",
                "import ipywidgets as widgets\n",
                "import librosa\n",
                "import torch\n",
                "from IPython.display import Audio, Markdown, display\n",
                "from transformers import WhisperForConditionalGeneration, WhisperProcessor\n",
                "\n",
                "# Constants\n",
                "LANGUAGE = \"en\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3c76fc98",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Setup device\n",
                "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
                "print(f\"Using device: {device}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0f984ead",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Model setup - using Whisper small model for faster inference\n",
                "# Documentation: https://huggingface.co/openai/whisper-small\n",
                "model_id = \"openai/whisper-small\"\n",
                "\n",
                "processor = WhisperProcessor.from_pretrained(model_id)\n",
                "model = WhisperForConditionalGeneration.from_pretrained(\n",
                "    model_id, torch_dtype=torch.float16 if device == \"cuda\" else torch.float32\n",
                ")\n",
                "model.to(device)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "926033b0",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Helper Functions\n",
                "\n",
                "\n",
                "def create_audio_player(audio_path):\n",
                "    \"\"\"Create an interactive audio player widget for the given audio file.\"\"\"\n",
                "    play_button = widgets.Button(description=\"Play Audio\")\n",
                "\n",
                "    def on_play_clicked(b):\n",
                "        display(Audio(audio_path))\n",
                "\n",
                "    play_button.on_click(on_play_clicked)\n",
                "    return play_button\n",
                "\n",
                "\n",
                "def transcribe_audio(audio_path, processor, model, device):\n",
                "    \"\"\"Transcribe audio file and return decoded outputs.\"\"\"\n",
                "    start_time = time.time()\n",
                "\n",
                "    # Load audio file\n",
                "    audio, sr = librosa.load(audio_path, sr=16000)\n",
                "\n",
                "    # Process audio with Whisper\n",
                "    inputs = processor(audio, sampling_rate=16000, return_tensors=\"pt\")\n",
                "    inputs = inputs.to(device)\n",
                "\n",
                "    # Ensure input features match model dtype\n",
                "    if device == \"cuda\":\n",
                "        inputs.input_features = inputs.input_features.to(torch.float16)\n",
                "\n",
                "    # Generate transcription\n",
                "    with torch.no_grad():\n",
                "        outputs = model.generate(inputs.input_features, max_new_tokens=400)\n",
                "\n",
                "    end_time = time.time()\n",
                "    elapsed_time = end_time - start_time\n",
                "    print(f\"Transcription completed in {elapsed_time:.2f} seconds\")\n",
                "\n",
                "    return processor.batch_decode(outputs, skip_special_tokens=True)\n",
                "\n",
                "\n",
                "def display_transcription(decoded_outputs):\n",
                "    \"\"\"Display transcription results with consistent formatting.\"\"\"\n",
                "    print(\"\\nTranscribed responses:\")\n",
                "    print(\"=\" * 80)\n",
                "    for decoded_output in decoded_outputs:\n",
                "        display(Markdown(decoded_output))\n",
                "        print(\"=\" * 80)\n",
                "\n",
                "\n",
                "def process_audio_file(audio_config, processor, model, device):\n",
                "    \"\"\"Process a single audio file: display info, player, and transcription.\"\"\"\n",
                "    # Display audio file information\n",
                "    display(Markdown(f\"### {audio_config['title']}\"))\n",
                "    display(Markdown(f\"**Recording length:** {audio_config['length']}\"))\n",
                "    display(Markdown(f\"**Original text:**\\n> {audio_config['original']}\"))\n",
                "\n",
                "    # Create and display audio player\n",
                "    player = create_audio_player(audio_config[\"path\"])\n",
                "    display(player)\n",
                "\n",
                "    # Transcribe and display results\n",
                "    decoded_outputs = transcribe_audio(audio_config[\"path\"], processor, model, device)\n",
                "    display_transcription(decoded_outputs)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "49f7f168",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Audio Files Configuration\n",
                "audio_files = [\n",
                "    # {\n",
                "    #     \"title\": \"Audio file #1: Frying Pan\",\n",
                "    #     \"path\": \"../audio/frying-pan.mp3\",\n",
                "    #     \"length\": \"39 seconds\",\n",
                "    #     \"original\": \"Okay. Wow, I think what I'm seeing again is what I've described before. Ok. Are you try, are you going to try to describe it again? Frying pan , the first thing I described. Is it exactly the first one you described? Yeah, but let me describe again in case you got it wrong, I don't know. The the background is a green, like a green rug, or green material, then there's a frying pan on it. The frying pan is, the inside is black, the body is red. Then inside that frying pan, there are some fried things that are like chicken or donut Ok Inside it, you'll still see a small bowl, it has yellow something inside it Ok, its the same thing. I've\",\n",
                "    # },\n",
                "    # {\n",
                "    #     \"title\": \"Audio file #2: Mary Had a Little Lamb\",\n",
                "    #     \"path\": \"../audio/mary-had-a-little-lamb.mp3\",\n",
                "    #     \"length\": \"16 seconds\",\n",
                "    #     \"original\": \"The first words I spoke in the original phonograph. Eh, a little piece of practical poetry. Mary had a little lamb, its fleece was white as snow, and everywhere that Mary went, the lamb was sure to go.\",\n",
                "    # },\n",
                "    # {\n",
                "    #     \"title\": \"Audio file #3: Barcelona Weather\",\n",
                "    #     \"path\": \"../audio/barcelona-weather.mp3\",\n",
                "    #     \"length\": \"11 seconds\",\n",
                "    #     \"original\": \"Yesterday it was thirty-five degrees in Barcelona, but today the temperature will go down to minus twenty degrees.\",\n",
                "    # },\n",
                "    # {\n",
                "    #     \"title\": \"Audio file #4: Phone Call\",\n",
                "    #     \"path\": \"../audio/phone-call.mp3\",\n",
                "    #     \"length\": \"25 seconds\",\n",
                "    #     \"original\": \"This is the full reflection. Ok. Because the water is kind of boiling. Ok. So this is a bird the bird is black and blue. It's facing, its face is facing us but its full physique is facing left. Okay, yes.\",\n",
                "    # },\n",
                "    # {\n",
                "    #     \"title\": \"Audio file #5: Brunei Gallery\",\n",
                "    #     \"path\": \"../audio/brunei-gallery.mp3\",\n",
                "    #     \"length\": \"25 seconds\",\n",
                "    #     \"original\": \"The Brunei gallery hosts a programme of changing contemporary and historical exhibitions from Asia Africa and the Middle East\",\n",
                "    # },\n",
                "    {\n",
                "        \"title\": \"Audio file #6: Jollof in the Oven\",\n",
                "        \"path\": \"../audio/jollof.mp3\",\n",
                "        \"length\": \"3 seconds\",\n",
                "        \"original\": \"I like cooking my jollof rice in the oven\",\n",
                "    },\n",
                "    {\n",
                "        \"title\": \"Audio file #7: Edikaikong Soup\",\n",
                "        \"path\": \"../audio/edikaikong.mp3\",\n",
                "        \"length\": \"6 seconds\",\n",
                "        \"original\": \"Edikaikong is a vegetable soup which originated with the Annang Ibibio and Efik people\",\n",
                "    },\n",
                "]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e0c6a2a7",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Process All Audio Files\n",
                "# This replaces all the individual audio processing cells with a clean loop\n",
                "\n",
                "for audio_config in audio_files:\n",
                "    process_audio_file(audio_config, processor, model, device)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b81943c2",
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "jupytext": {
            "cell_metadata_filter": "-all",
            "formats": "auto:percent,ipynb",
            "main_language": "python",
            "notebook_metadata_filter": "-all"
        },
        "kernelspec": {
            "display_name": "project-name",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.11"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
